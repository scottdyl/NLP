{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fbcbb8c",
   "metadata": {},
   "source": [
    "1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "\n",
    "a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceaf9d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('All', 'ABN'),\n",
       " ('a', 'AT'),\n",
       " ('man', 'NN'),\n",
       " ('really', 'RB'),\n",
       " ('needs', 'NNS'),\n",
       " ('is', 'BEZ'),\n",
       " ('a', 'AT'),\n",
       " ('horse', 'NN'),\n",
       " ('you', 'PPSS'),\n",
       " ('can', 'MD'),\n",
       " ('catch', 'VB'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PPSS'),\n",
       " ('need', 'VB'),\n",
       " ('him', 'PPO'),\n",
       " ('a', 'AT'),\n",
       " ('dog', 'NN'),\n",
       " ('that', 'CS'),\n",
       " ('comes', 'VBZ'),\n",
       " ('when', 'WRB'),\n",
       " ('you', 'PPSS'),\n",
       " ('call', 'VB'),\n",
       " ('a', 'AT'),\n",
       " ('good', 'JJ'),\n",
       " ('friend', 'NN'),\n",
       " ('that', 'CS'),\n",
       " ('owns', 'VBZ'),\n",
       " ('an', 'AT'),\n",
       " ('arena', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('trailer', 'NN'),\n",
       " ('that', 'CS'),\n",
       " ('is', 'BEZ'),\n",
       " ('legal', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('haul', 'VB')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "sentence = 'All a man really needs is a horse you can catch when you need him, a dog that comes when you call, a good friend that owns an arena and trailer that is legal to haul.'\n",
    "\n",
    "#clean string\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "sentence = re.sub(pat, '', sentence)\n",
    "\n",
    "#split string\n",
    "splits = sentence.split()\n",
    "\n",
    "unigram_tagger.tag(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e259f7f",
   "metadata": {},
   "source": [
    "This is one of my favorite quotes by Red Steagall and I think it is properly tagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26fc5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Everything', 'PN'),\n",
       " ('else', 'RB'),\n",
       " ('is', 'BEZ'),\n",
       " ('window', 'NN'),\n",
       " ('dressing', 'VBG')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "sentence = 'Everything else is window dressing'\n",
    "\n",
    "#clean string\n",
    "pat = re.compile(r'[^a-zA-Z ]+')\n",
    "sentence = re.sub(pat, '', sentence)\n",
    "\n",
    "#split string\n",
    "splits = sentence.split()\n",
    "\n",
    "unigram_tagger.tag(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c942e0",
   "metadata": {},
   "source": [
    "The short sentence above is tricky to tag since in this case ‘window dressing’ is a noun and not a noun verb combo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460deb1",
   "metadata": {},
   "source": [
    "2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "a.\tDoes it produce the same or different output?\n",
    "\n",
    "b.\tExplain any differences as best you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a413435d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  All/PDT\n",
      "  (NP a/DT man/NN)\n",
      "  really/RB\n",
      "  needs/VBZ\n",
      "  is/VBZ\n",
      "  (NP a/DT horse/NN)\n",
      "  you/PRP\n",
      "  can/MD\n",
      "  catch/VB\n",
      "  when/WRB\n",
      "  you/PRP\n",
      "  need/VBP\n",
      "  him/PRP\n",
      "  ,/,\n",
      "  (NP a/DT dog/NN)\n",
      "  that/WDT\n",
      "  comes/VBZ\n",
      "  when/WRB\n",
      "  you/PRP\n",
      "  call/VBP\n",
      "  ,/,\n",
      "  (NP a/DT good/JJ friend/NN)\n",
      "  that/WDT\n",
      "  owns/VBZ\n",
      "  (NP an/DT arena/NN)\n",
      "  and/CC\n",
      "  (NP trailer/NN)\n",
      "  that/WDT\n",
      "  is/VBZ\n",
      "  legal/JJ\n",
      "  to/TO\n",
      "  haul/VB\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "sentence = 'All a man really needs is a horse you can catch when you need him, a dog that comes when you call, a good friend that owns an arena and trailer that is legal to haul.'\n",
    "sentence2 = 'Everything else is window dressing'\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "text = nltk.word_tokenize(sentence)\n",
    "text = nltk.pos_tag(text)\n",
    "result = cp.parse(text)\n",
    "print(result)\n",
    "#result.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a1a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Everything/NN) else/RB is/VBZ window/JJ dressing/VBG)\n"
     ]
    }
   ],
   "source": [
    "sentence2 = 'Everything else is window dressing'\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "text = nltk.word_tokenize(sentence2)\n",
    "text = nltk.pos_tag(text)\n",
    "result = cp.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d839f1",
   "metadata": {},
   "source": [
    "For the long sentence the two tokenizers produce the same result. The second parser was a bit more detailed by identifying phrases, but the overall result was the same. For the shorter sentence the second parser identified the word ‘window as JJ which was specifically identified in the grammar to view NN as JJ. Therefore, not much difference there either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d8e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Everything/NN) else/RB is/VBZ window/JJ dressing/VBG)\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "sentence = 'Everything else is window dressing'\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "text = nltk.word_tokenize(sentence)\n",
    "text = nltk.pos_tag(text)\n",
    "result = cp.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7c575",
   "metadata": {},
   "source": [
    "3.\tIn a news article from this week’s news, find a random sentence of at least 10 words.\n",
    "\n",
    "a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "\n",
    "c.\tExplain any differences between the two taggers and your manual tagging as much as you can.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb6855",
   "metadata": {},
   "source": [
    "My output: \n",
    "[('The', 'DT'),\n",
    " ('evolving', 'VBG'),\n",
    " ('style', 'NN'),\n",
    " ('of', 'IN'),\n",
    " ('this', 'DT'),\n",
    " ('growing', 'VBG'),\n",
    " ('city', 'NN'),\n",
    " ('will', 'MD'),\n",
    " ('take', 'VB'),\n",
    " ('center', 'NN'),\n",
    " ('stage', 'NN'),\n",
    " ('with', 'IN'),\n",
    " ('a', 'DT'),\n",
    " ('first-of-its-kind', 'NP'),\n",
    " ('fashion', 'NN'),\n",
    " ('week', 'NN'),\n",
    " (',', ','),\n",
    " ('spearheaded', 'VBN'),\n",
    " ('by', 'IN'),\n",
    " ('local', 'JJ'),\n",
    " ('designer', 'NN'),\n",
    " ('Phillip', 'NNP'),\n",
    " ('Maximilian', 'NNP'),\n",
    " ('.', '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b482c544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('evolving', 'VBG'),\n",
       " ('style', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('growing', 'VBG'),\n",
       " ('city', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('center', 'NN'),\n",
       " ('stage', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('first-of-its-kind', 'JJ'),\n",
       " ('fashion', 'NN'),\n",
       " ('week', 'NN'),\n",
       " (',', ','),\n",
       " ('spearheaded', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('local', 'JJ'),\n",
       " ('designer', 'NN'),\n",
       " ('Phillip', 'NNP'),\n",
       " ('Maximilian', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gosh the news is sad these days. Let me see if I can find something more uplifting\n",
    "sentence = 'The evolving style of this growing city will take center stage with a first-of-its-kind fashion week, spearheaded by local designer Phillip Maximilian.'\n",
    "text = nltk.word_tokenize(sentence)\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f23cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('evolving', 'VBG'),\n",
       " ('style', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('growing', 'VBG'),\n",
       " ('city', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('center', 'NN'),\n",
       " ('stage', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('a', 'AT'),\n",
       " ('first-of-its-kind', None),\n",
       " ('fashion', 'NN'),\n",
       " ('week', 'NN'),\n",
       " (',', ','),\n",
       " ('spearheaded', None),\n",
       " ('by', 'IN'),\n",
       " ('local', 'JJ'),\n",
       " ('designer', 'NN'),\n",
       " ('Phillip', 'NP'),\n",
       " ('Maximilian', 'NP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b301d0",
   "metadata": {},
   "source": [
    "I think the biggest difference between the two taggers and my own tagging came with the phrase ‘one-of-a-kind’ since the article used a hyphenated version of this noun phrase one of the parsers did not give it a typing and the other determined it was a JJ. I personally though it was a noun phrase that could be parsed even further since it is hyphenated. Other than that both parsers and I agreed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
