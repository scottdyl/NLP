{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d0fc76",
   "metadata": {},
   "source": [
    "## Dylan Scott\n",
    "### Homwork 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a917b8e",
   "metadata": {},
   "source": [
    "1.\tInstall Python (if you don’t have it already), and install NLTK.  \n",
    "\n",
    "2.\tFollow the instructions in chapter 1 of Bird-Klein for implementing a “lexical diversity” scoring routine.\n",
    "\n",
    "3.\tGo to http://www.gutenberg.org/wiki/Children%27s_Instructional_Books_(Bookshelf), and obtain three texts (of different grade levels) from the “Graded Readers” section. Report the lexical diversity score of each. Explain whether the result was surprising.\n",
    "\n",
    "4.\tAlso compare the vocabulary size of the same three texts. Explain whether the result was surprising.  \n",
    "\n",
    "5.\tWrite a paragraph arguing whether vocabulary size and lexical diversity in combination could be a better measure of text difficulty (or reading level) than either measure is by itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191373a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e385167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "    \n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9893cc6",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ae9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second\n",
    "second=open('C:/Users/drsco/Documents/GitHub/NLP/second_reader.txt','r',encoding=\"ISO-8859-1\").read()\n",
    "tokens = nltk.word_tokenize(second)\n",
    "second_t = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f703a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth\n",
    "fourth=open('C:/Users/drsco/Documents/GitHub/NLP/fourth_reader.txt','r',encoding=\"utf8\").read()\n",
    "tokens = nltk.word_tokenize(fourth)\n",
    "fourth_t = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d7aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth\n",
    "sixth=open('C:/Users/drsco/Documents/GitHub/NLP/sixth_reader.txt','r',encoding=\"utf8\").read()\n",
    "tokens = nltk.word_tokenize(sixth)\n",
    "sixth_t = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26d5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sixth\n",
    "high=open('C:/Users/drsco/Documents/GitHub/NLP/high.txt','r',encoding=\"utf8\").read()\n",
    "tokens = nltk.word_tokenize(high)\n",
    "high_t = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f21431",
   "metadata": {},
   "source": [
    "### Laxical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e93e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1589006476070131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(second_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de74849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1128618252181811"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(fourth_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b199260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10087260442906655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(sixth_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b540c",
   "metadata": {},
   "source": [
    "For this project I tried to use text that would be similar but at different grade intervals. Upon the initial results I am surprised that the second-grade text scored higher on the lexical diversity relative to the fourth grade and sixth grade options. When looking at the vocab size vs overall length I am no longer surprised by this result. The second-grade text had a lower ratio of word length to vocab size which helps explain the higher lexical diversity.\n",
    "\n",
    "Looking at the lexical diversity for each text independently like previously stated I thought the sixth-grade text would have the highest lexical diversity. I figured that as the text increased in recommended grade that the lexical diversity would also be higher. The overall scores of each text were not surprising since they all cover similar topics throughout. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbd316",
   "metadata": {},
   "source": [
    "### Vocab Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1477d05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 Vocabulary Size: 4024\n",
      "Text 2 Vocabulary Size: 14290\n",
      "Text 3 Vocabulary Size: 17259\n",
      "Text 1 overall Length: 25324\n",
      "Text 2 overall Length: 126615\n",
      "Text 3 overall Length: 171097\n"
     ]
    }
   ],
   "source": [
    "print(\"Text 1 Vocabulary Size:\",len(set(second_t)))\n",
    "print(\"Text 2 Vocabulary Size:\",len(set(fourth_t)))\n",
    "print(\"Text 3 Vocabulary Size:\",len(set(sixth_t)))\n",
    "\n",
    "print(\"Text 1 overall Length:\",len(second_t))\n",
    "print(\"Text 2 overall Length:\",len(fourth_t))\n",
    "print(\"Text 3 overall Length:\",len(sixth_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3efc29c",
   "metadata": {},
   "source": [
    "Looking at vocab size we can see that the second-grade text has the lowest which is to be expected not only because of the grade but also considering the overall size of each text. The second-grade text also had the lowest ratio of vocab size to overall length meaning it took less tokens to produce a unique word. Given the grades that these texts are for I am not surprised by the length nor the vocab size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5bbfd",
   "metadata": {},
   "source": [
    "### Text Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70363f2a",
   "metadata": {},
   "source": [
    "Regarding overall text difficulty I could consider lexical diversity to be the better static. Both lexical diversity and vocab size have their place but just because a text has a large vocab size does not mean it is particularly difficult. Within the English language we have synonyms and antonyms which can give context clues and lower the difficulty of the text. lexical diversity show the ratio of different unique words within a text but it also accounts for the repeated words. Once a student faces a term once within a text, they should be equipped to handle its context again. This is what gives lexical diversity over vocab count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e2a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
