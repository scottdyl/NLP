{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a83b19",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "1.\tCompare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "\n",
    "a.\tWhat is the edit distance between your nickname and your given name?\n",
    "\n",
    "b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "Show your work for both calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c08b9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707d07d",
   "metadata": {},
   "source": [
    "nltk reference\n",
    "https://www.nltk.org/_modules/nltk/metrics/distance.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8d1264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance:  4\n"
     ]
    }
   ],
   "source": [
    "#part a\n",
    "\n",
    "name = 'dylan'\n",
    "nickname = 'doc'\n",
    "\n",
    "def _edit_dist_init(len1, len2):\n",
    "    lev = []\n",
    "    for i in range(len1):\n",
    "        lev.append([0] * len2)  # initialize 2D array to zero\n",
    "    for i in range(len1):\n",
    "        lev[i][0] = i  # column 0: 0,1,2,3,4,...\n",
    "    for j in range(len2):\n",
    "        lev[0][j] = j  # row 0: 0,1,2,3,4,...\n",
    "    return lev\n",
    "\n",
    "\n",
    "def _edit_dist_step(lev, i, j, s1, s2, substitution_cost=1, transpositions=False):\n",
    "    c1 = s1[i - 1]\n",
    "    c2 = s2[j - 1]\n",
    "\n",
    "    # skipping a character in s1\n",
    "    a = lev[i - 1][j] + 1\n",
    "    # skipping a character in s2\n",
    "    b = lev[i][j - 1] + 1\n",
    "    # substitution\n",
    "    c = lev[i - 1][j - 1] + (substitution_cost if c1 != c2 else 0)\n",
    "\n",
    "    # transposition\n",
    "    d = c + 1  # never picked by default\n",
    "    if transpositions and i > 1 and j > 1:\n",
    "        if s1[i - 2] == c2 and s2[j - 2] == c1:\n",
    "            d = lev[i - 2][j - 2] + 1\n",
    "\n",
    "    # pick the cheapest\n",
    "    lev[i][j] = min(a, b, c, d)\n",
    "    \n",
    "def edit_distance(string1, string2, substitution_cost=1, transpositions=False):\n",
    "\n",
    "    # set up a 2-D array\n",
    "    len1 = len(string1)\n",
    "    len2 = len(string2)\n",
    "    lev = _edit_dist_init(len1 + 1, len2 + 1)\n",
    "\n",
    "    # iterate over the array\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            _edit_dist_step(\n",
    "                lev,\n",
    "                i + 1,\n",
    "                j + 1,\n",
    "                string1,\n",
    "                string2,\n",
    "                substitution_cost=substitution_cost,\n",
    "                transpositions=transpositions,\n",
    "            )\n",
    "    return lev[len1][len2]\n",
    "\n",
    "\n",
    "editDistance = edit_distance(name, nickname)\n",
    "print(\"Edit Distance: \", editDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c54f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2b2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "#part b\n",
    "name = 'dylan'\n",
    "nickname = 'doc'\n",
    "match = similar(name,nickname)\n",
    "print(\"percent match\",match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683afc7c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb83bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harry Potter and the Sorcer's Stone\n",
    "text = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
    "text_tokens  = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3206d1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Mr.\\', \\'Mrs.\\', \\'Dursley\\', \\',\\', \\'number\\', \\'four\\', \\',\\', \\'Privet\\', \\'Drive\\', \\',\\', \\'proud\\', \\'say\\', \\'perfectly\\', \\'normal\\', \\',\\', \\'thank\\', \\'much\\', \\'.\\', \\'They\\', \\'last\\', \\'people\\', \"\\'d\", \\'expect\\', \\'involved\\', \\'anything\\', \\'strange\\', \\'mysterious\\', \\',\\', \"n\\'t\", \\'hold\\', \\'nonsense\\', \\'.\\']'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d5c9d",
   "metadata": {},
   "source": [
    "I quizzed my girlfriend who recently read the first Harry Potter book. She got it within the first 3 words which were the names of main characters throughout the series. However, without those character I do not think she would have known which book it was. The next series of words was their address of number four Privet drive which is quite substantial information for understanding the book quizzed. The last bit of info left to tell it was a Harry Potter book was “perfectly normal” and “mysterious” and “strange” "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2fdbc1",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2048cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.  :  mr.\n",
      "and  :  and\n",
      "Mrs.  :  mrs.\n",
      "Dursley  :  dursley\n",
      ",  :  ,\n",
      "of  :  of\n",
      "number  :  number\n",
      "four  :  four\n",
      ",  :  ,\n",
      "Privet  :  privet\n",
      "Drive  :  drive\n",
      ",  :  ,\n",
      "were  :  were\n",
      "proud  :  proud\n",
      "to  :  to\n",
      "say  :  say\n",
      "that  :  that\n",
      "they  :  they\n",
      "were  :  were\n",
      "perfectly  :  perfectli\n",
      "normal  :  normal\n",
      ",  :  ,\n",
      "thank  :  thank\n",
      "you  :  you\n",
      "very  :  veri\n",
      "much  :  much\n",
      ".  :  .\n",
      "They  :  they\n",
      "were  :  were\n",
      "the  :  the\n",
      "last  :  last\n",
      "people  :  peopl\n",
      "you  :  you\n",
      "'d  :  'd\n",
      "expect  :  expect\n",
      "to  :  to\n",
      "be  :  be\n",
      "involved  :  involv\n",
      "in  :  in\n",
      "anything  :  anyth\n",
      "strange  :  strang\n",
      "or  :  or\n",
      "mysterious  :  mysteri\n",
      ",  :  ,\n",
      "because  :  becaus\n",
      "they  :  they\n",
      "just  :  just\n",
      "did  :  did\n",
      "n't  :  n't\n",
      "hold  :  hold\n",
      "with  :  with\n",
      "such  :  such\n",
      "nonsense  :  nonsens\n",
      ".  :  .\n"
     ]
    }
   ],
   "source": [
    "#Harry Potter and the Sorcer's Stone\n",
    "text = \"Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords  \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "\n",
    "text_token = word_tokenize(text)\n",
    "\n",
    "for w in text_token: \n",
    "    print(w, \" : \", ps.stem(w)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9a6e7",
   "metadata": {},
   "source": [
    "I used the porter stemmer in python. Looking at the results above we see some interesting results. Many of the words that end in y were replaced with words ending in i. I would consider the word involved to be a valid stem but overall less than 5% of these words are valid stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1dd50b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
